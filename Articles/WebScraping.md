# Web Scraping

## What it is Web Scraping?

Sometimes, we don't have a public API to get information and the only way to obtain it, is to visit some website that has that specific info.
But what if we managed to obtain that specific piece of data from not only one website, but many? That's when Web Scraping appears.

**Web scraping**, **web harvesting** or **web data extraction** is data scraping used for extrating data from websites.
Web scraping software many access the World Wide Web directly using the HTTP (Hypertext Transfer Protocol), or through a web browser. The term usually refers to automated processes implemented using a bot or web crawler. It's a form of copying, in which specific data is gathered and copied from the web, for later retrieval or analysis.

## Fetching and Extracting

Web scraping a web page involves fetching it and extracting from it. **Fetching** is the downloading of a page (which a browser does when an user views a page). Therefore, web crawling is a main component of web scraping, to fetch pages for later processing. Once fetched, the **extraction** can take place. The content of a page my be parsed, searched, reformatted, its data copied into a spreadsheet, and so on. Web scrapers typically take something out of a page to make use of it for another purpose somewhere else.

Web scraping is used for contact scraping, and as a component of applications used for web indexing, web mining and data mining, online price change monitoring and price comparison, product review scraping, gathering real state listings, weather data monitoring, website change detection, research, tracking online presence and reputation, web mashup and web data integration.

**JSON** is commonly used as a transport storage mechanism between the client and the web server.

There are methods that some websites use to prevent scraping, such as detecting and disallowing bots from crawling their pages. In response, there are web scraping systems that rely on using techniques in DOM parsing, computer vision and natural language processing to simulate human browsing to enable gathering web page content for offline parsing.


## Some techniques

#### Text pattern matching
A powerful approach to extract information from web pages can be based on the UNIX grep command or regular expression-matching facilities of programming languages (Shell, Python).


#### HTTP programming
Static and dynamic web pages can be retrieved by posting HTTP request to the remote web server using socket programming.


#### DOM parsing
By embedding a full-fledged web browser, programs can retrieve the dynamic content generated by client-side scripts. These browsers controls also parse web pages into a DOM tree, based on which programs can retrieve parts of the pages.


## Methods to prevent web scraping

- Blocking an IP address manually or based on geolocation. This will block all browsing from that address.
- Disabling any web service API that could be exposed.
- Bots sometimes declare who they are and can be blocked.
- Bots can be blocked by monitoring excess traffic.
- Bots can sometimes be blocked with tools to verify that its a real person accessing the site, like a CAPTCHA.
- Locating bots with a honeypot or other method to identify the IP addresses of automated crawlers.
- Websites can declare if crawling is allowed or not in the robots.txt file and allow partial access, limit the crawl rate, specify the optimal time to crawl, etc.




##### [Web scraping - Wikipedia](https://en.wikipedia.org/wiki/Web_scraping) / Wikipedia
##### [What is Web Scraping and How to Use it](https://www.geeksforgeeks.org/what-is-web-scraping-and-how-to-use-it/) / Brief explanation on web scraping